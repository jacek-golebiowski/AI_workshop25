CLEAR

About This Project

This project features a custom implementation of the CLEAR algorithm (Counterfactual Local Explanations via Regression), entirely rewritten from scratch in PyTorch and tailored specifically for image anomaly detection using the MVTec dataset.

While the original CLEAR [(White et al., 2019)](https://arxiv.org/abs/2106.14556) was developed for tabular data and relied on TensorFlow, this version adapts the core methodology to operate within the latent space of an AutoEncoder trained on image data. It produces **visually interpretable counterfactual images** that explain classification decisions by answering: _"what minimal change would flip this classification?"_

---

How It Works

1. AutoEncoder Training
A convolutional AutoEncoder is trained on MVTec grayscale images (resized to 128×128), compressing them into a 64-dimensional latent space. The decoder learns to reconstruct images from this compressed representation.

2. CNN Classifier Training
A lightweight convolutional classifier is trained to distinguish between _normal_ and _anomalous_ images from the dataset.

3. Image Selection
From the MVTec test set, one normal and one anomalous image are selected as input examples.

4. Latent Sampling + Regression (CLEAR)
- The image is encoded into latent space.
- Thousands of latent vectors are sampled from a local Gaussian distribution around it.
- Each vector is decoded and passed through the classifier.
- The classifier's predicted labels are used to train a **local logistic regression model** in latent space.

5. Counterfactual Generation
- A target class is defined (e.g., flip anomaly → normal).
- CLEAR computes the minimal direction (Δz) in latent space that crosses the decision boundary.
- The modified latent vector is decoded into a counterfactual image.

6. Visualization
- The original image, counterfactual image, and their pixel-wise difference map are saved.
- Classifier predictions are printed for both original and counterfactual.
- All results are saved under `./generatedImages`.

---

How to run

python3 -m venv clear-env

source clear-env/bin/activate.fish

pip install --upgrade pip
pip install -r requirements.txt

cd clear

make run DATASET_NAME=carpet



DICE

About This Project
This part of the project demonstrates the use of the DiCE (Diverse Counterfactual Explanations) library for generating counterfactuals in image anomaly detection using the MVTec dataset.

While DiCE was originally designed for tabular data, here it has been adapted to work with images via preprocessing into a reduced latent representation using Principal Component Analysis (PCA). After compression, DiCE operates directly on this low-dimensional tabular form.

How It Works
1. CNN Classifier Training

A lightweight convolutional classifier (SimpleCNN) is trained on MVTec grayscale images (resized to 128×128) to distinguish between normal and anomalous samples. The model is saved to pthFiles/.

2. PCA Dimensionality Reduction

Flattened images (128×128 → 16384 features) are reduced to 64 principal components using PCA (Principal Component Analysis).
This converts image data into a tabular form suitable for DiCE.
3. DiCE Model Wrapping

The PyTorch model is wrapped to interface with DiCE's explainer. DiCE operates in PCA space.

4. Counterfactual Generation

For each query image, DiCE attempts to generate counterfactuals that flip the class (e.g. anomaly → normal).
Due to the dataset structure, DiCE successfully generates anomaly → normal counterfactuals, but struggles to find valid solutions for normal → anomaly.
The generated counterfactuals are decoded back to image space using inverse PCA.
5. Visualization

The original image, counterfactual image, and pixel-wise difference map are displayed and saved.
All results are saved under ./generatedImages.



How to run
Create environment and install dependencies:

python3 -m venv dice-env
source dice-env/bin/activate.fish

pip install --upgrade pip
pip install -r requirements.txt



Run on single dataset:

make run DATASET_NAME=bottle



Run full batch on all datasets: (This part is present but commented in the Makefile — you can enable it if needed.)

make run_all

This will automatically iterate over all 15 categories and generate counterfactuals for each.